# Voice-Lens: AI 시각 보조 음성 서비스

시각장애인을 위한 상황별 맞춤형 AI 해설 서비스입니다. 사용자가 이미지를 업로드하면, AI가 이미지의 상황과 내용을 분석하여 상세한 설명을 음성으로 들려주는 풀스택(Full-stack) 웹 애플리케이션입니다.

## 🚀 주요 기능

- **🧠 AI 이미지 분석:** Google Gemini 모델을 활용하여 이미지에 대한 풍부하고 구체적인 설명을 한국어로 생성합니다.
- **🔊 실시간 음성 출력:** 생성된 텍스트 설명을 자연스러운 목소리로 변환하여, 분석 직후 사용자에게 자동으로 음성을 재생해 줍니다.
- **🌐 간결한 웹 인터페이스:** Streamlit으로 구축된 직관적인 UI를 통해 누구나 쉽게 이미지를 업로드하고 결과를 확인할 수 있습니다.

## ⚙️ 시스템 아키텍처

이 프로젝트는 다음과 같이 프론트엔드와 백엔드가 분리된 구조로 설계되었습니다.

1.  **Frontend (Streamlit):**
    -   사용자가 이미지를 업로드하는 웹 인터페이스를 제공합니다.
    -   백엔드 API에 분석을 요청하고, 반환된 설명 텍스트와 음성을 사용자에게 제공합니다.

2.  **Backend (FastAPI):**
    -   프론트엔드로부터 이미지를 받아 처리하는 고성능 비동기 API 서버입니다.
    -   AI 서비스와 TTS 서비스를 조율(Orchestration)하여 핵심 비즈니스 로직을 수행합니다.
    -   **AI Service:** Google Gemini API와 통신하여 이미지 설명을 생성합니다.
    -   **TTS Service:** gTTS 라이브러리를 사용하여 텍스트를 MP3 음성 파일로 변환합니다.

## 💡 동작 방식

1.  사용자가 Streamlit 웹 앱에 접속하여 이미지를 업로드합니다.
2.  프론트엔드는 이미지를 FastAPI 백엔드의 `/analyze` 엔드포인트로 전송합니다.
3.  백엔드는 이미지를 받은 후, AI 서비스를 호출하여 설명을 생성합니다.
4.  생성된 텍스트를 TTS 서비스를 통해 음성 파일로 변환하고, 생성된 파일의 URL을 프론트엔드에 반환합니다.
5.  프론트엔드는 백엔드로부터 받은 설명 텍스트를 화면에 표시하고, 음성 파일 URL을 통해 오디오를 자동으로 재생합니다.
